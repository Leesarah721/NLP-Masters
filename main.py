# main.py

import streamlit as st
from streaming import StreamHandler  # ì›ë³¸ì—ì„œ ì‚¬ìš©ë˜ì—ˆë‹¤ê³  ê°€ì •
import module_a
import module_b
import module_c
import module_d
import utils

# LangSmith tracking (ì›ë³¸ ì½”ë“œ)
from langchain_teddynote import logging
logging.langsmith("LANCHAIN-PROJECT")

# Streamlit ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ChatPDF", page_icon="ğŸ“„")
st.header('ğŸ“„ì²­ì•½ìŠ¤ìºë„ˆ')
st.write('í•´ë‹¹ ì²­ì•½ ê³µê³ ë¬¸ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•´ë³´ì„¸ìš”!')
st.write('[![view source code ](https://img.shields.io/badge/view_source_code-gray?logo=github)](https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/4_%F0%9F%93%84_chat_with_your_documents.py)')

@utils.enable_chat_history
def main():
    # ì„¸ì…˜ ë™ê¸°í™”
    utils.sync_st_session()

    # 1) ì‚¬ì´ë“œë°”ì—ì„œ PDF ì—…ë¡œë“œ
    uploaded_files = st.sidebar.file_uploader(
        label='Upload PDF files',
        type=['pdf'],
        accept_multiple_files=True
    )
    if not uploaded_files:
        st.error("ê³µê³ ë¬¸ì„ PDF íŒŒì¼ë¡œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
        st.stop()

    # 2) ëª¨ë¸(LLM) ì„ íƒ
    llm = module_d.select_llm_model()
    # ë˜ëŠ”: llm = utils.configure_llm()

    # ì´ë¯¸ ìƒì„±ëœ ë¬¸ì„œ/ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ê±°ë‚˜, ì—…ë¡œë“œëœ íŒŒì¼ì´ ë°”ë€ ê²½ìš°ì—ë§Œ ì¬ìƒì„±
    uploaded_file_names = [f.name for f in uploaded_files]
    if (
        "docs" not in st.session_state or
        "splits" not in st.session_state or
        "vectordb" not in st.session_state or
        "uploaded_file_names" not in st.session_state or
        st.session_state["uploaded_file_names"] != uploaded_file_names
    ):
        with st.spinner("Loading and splitting documents..."):
            docs = module_a.load_pdfs(uploaded_files)
            splits = module_a.split_documents(docs)

        with st.spinner("Creating embeddings & vector store..."):
            embedding_model = module_b.create_embedding_model()
            vectordb = module_b.create_vectorstore(splits, embedding_model)

        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•˜ì—¬ ì¬ì‚¬ìš©
        st.session_state["docs"] = docs
        st.session_state["splits"] = splits
        st.session_state["vectordb"] = vectordb
        st.session_state["uploaded_file_names"] = uploaded_file_names
    else:
        docs = st.session_state["docs"]
        splits = st.session_state["splits"]
        vectordb = st.session_state["vectordb"]

    # 5) Retriever, Memory, Conversational Chain êµ¬ì„±
    # retriever = module_c.create_retriever(vectordb, search_type='mmr', k=2, fetch_k=4)
    # memory = module_c.create_memory()
    # qa_chain = module_c.create_conversational_chain(llm, retriever, memory, verbose=False)

    # 6) ì‚¬ìš©ì Query
    user_query = st.chat_input(placeholder="ë¬´ì—‡ì´ë“  ì§ˆë¬¸í•´ë³´ì„¸ìš”!")
    if user_query:
        utils.display_msg(user_query, 'user')

        # 7) LLMì— ì§ˆë¬¸ì„ ì „ë‹¬ â†’ RAG ì²´ì¸ìœ¼ë¡œ ë‹µë³€ ìƒì„±
        with st.chat_message("assistant"):
            
            # 5) Retriever, Memory, Conversational Chain êµ¬ì„±
            dense_retriever, sparse_retriever = module_c.create_retriever(vectordb,'similarity', 3, 4,splits)
            memory = module_c.create_memory()
            qa_chain = module_c.create_conversational_chain(llm, dense_retriever, sparse_retriever, memory, False, user_query)

            st_cb = StreamHandler(st.empty())  # ìŠ¤íŠ¸ë¦¬ë° ì½œë°±
            result_answer, source_docs = module_d.generate_answer(qa_chain, user_query)

            # 8) ë‹µë³€ í‘œì‹œ
            st.session_state.messages.append({"role": "assistant", "content": result_answer})
            st.write(result_answer)

            # ë¡œê¹…
            utils.print_qa(main, user_query, result_answer)

            # 9) ì¶œì²˜ ë¬¸ì„œ(Reference) í‘œì‹œ
            for idx, doc in enumerate(source_docs, 1):
                filename = doc.metadata.get('source', 'unknown')
                page_num = doc.metadata.get('page', 'N/A')
                ref_title = f":blue[Reference {idx}: *{filename} - page.{page_num}*]"
                with st.popover(ref_title):
                    st.caption(doc.page_content)

if __name__ == "__main__":
    main()
